#define int8_t char
#define int16_t short
#define int32_t int
#define int64_t long
#define uint8_t uchar
#define uint16_t ushort
#define uint32_t uint
#define uint64_t ulong
#if defined(cl_khr_fp64)
#pragma OPENCL EXTENSION cl_khr_fp64 : enable
#define DOUBLE_SUPPORT_AVAILABLE
#elif defined(cl_amd_fp64)
#pragma OPENCL EXTENSION cl_amd_fp64 : enable
#define DOUBLE_SUPPORT_AVAILABLE
#endif
#if defined(cl_khr_fp16)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#define HALF_SUPPORT_AVAILABLE
#ifndef HALF_MAX
#define HALF_MAX 65504.f
#endif
#ifndef HALF_MIN
#define HALF_MIN 6.10352e-5f
#endif
#endif
#ifdef int_tp
#undef int_tp
#endif  //int_tp
#define int_tp int32_t
#ifdef uint_tp
#undef uint_tp
#endif  //uint_tp
#define uint_tp uint32_t
#ifdef int_tpc
#undef int_tpc
#endif  //int_tpc
#define int_tpc int32_t
#ifdef uint_tpc
#undef uint_tpc
#endif  //uint_tpc
#define uint_tpc uint32_t
#ifdef HALF_SUPPORT_AVAILABLE
#ifdef Dtype
#undef Dtype
#endif  //Dtype
#define Dtype half
__kernel
void caffe_gpu_set(const uint32_t n, const float alpha, __global half* y_raw_ptr, const uint_tp y_offset) {
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = alpha;
}
}
#ifdef Dtype
#undef Dtype
#endif  //Dtype
#define Dtype half
__kernel
void caffe_gpu_add_scalar(const uint32_t n, const float alpha, __global half* y_raw_ptr, const uint_tp y_offset) {
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] += alpha;
}
}
__kernel
void caffe_gpu_add(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global const half* b_raw_ptr, const uint_tp b_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global const half* b = b_raw_ptr + b_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = a[index] + b[index];
}
}
__kernel
void caffe_gpu_sub(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global const half* b_raw_ptr, const uint_tp b_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global const half* b = b_raw_ptr + b_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = a[index] - b[index];
}
}
__kernel
void caffe_gpu_mul(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global const half* b_raw_ptr, const uint_tp b_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global const half* b = b_raw_ptr + b_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = a[index] * b[index];
}
}
__kernel
void caffe_gpu_div(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global const half* b_raw_ptr, const uint_tp b_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global const half* b = b_raw_ptr + b_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = a[index] / b[index];
}
}
__kernel
void caffe_gpu_powx(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, const float alpha, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
if (alpha == (Dtype)2) {
y[index] = pow((Dtype)fabs(a[index]), (Dtype)alpha);
} else {
y[index] = pow((Dtype)a[index], (Dtype)alpha);
}
}
}
__kernel
void caffe_gpu_exp(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = exp(a[index]);
}
}
__kernel
void caffe_gpu_log(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = log(a[index]);
}
}
__kernel
void caffe_gpu_sqrt(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = sqrt(a[index]);
}
}
__kernel
void caffe_gpu_abs(const uint32_t n, __global const half* a_raw_ptr, const uint_tp a_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* a = a_raw_ptr + a_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = fabs(a[index]);
}
}
__kernel
void caffe_gpu_sign(const uint32_t n, __global const half* x_raw_ptr, const uint_tp x_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* x = x_raw_ptr + x_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = ((Dtype)0 < x[index]) - (x[index] < (Dtype)0);
}
}
__kernel
void caffe_gpu_signbit(const uint32_t n, __global const half* x_raw_ptr, const uint_tp x_offset, __global half* y_raw_ptr, const uint_tp y_offset) {
__global const half* x = x_raw_ptr + x_offset;
__global half* y = y_raw_ptr + y_offset;
for (uint_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
y[index] = signbit(x[index]);
}
}
#endif  // HALF_SUPPORT_AVAILABLE

#define int8_t char
#define int16_t short
#define int32_t int
#define int64_t long
#define uint8_t uchar
#define uint16_t ushort
#define uint32_t uint
#define uint64_t ulong
#if defined(cl_khr_fp64)
#pragma OPENCL EXTENSION cl_khr_fp64 : enable
#define DOUBLE_SUPPORT_AVAILABLE
#elif defined(cl_amd_fp64)
#pragma OPENCL EXTENSION cl_amd_fp64 : enable
#define DOUBLE_SUPPORT_AVAILABLE
#endif
#if defined(cl_khr_fp16)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#define HALF_SUPPORT_AVAILABLE
#ifndef HALF_MAX
#define HALF_MAX 65504.f
#endif
#ifndef HALF_MIN
#define HALF_MIN 6.10352e-5f
#endif
#endif
#ifdef int_tp
#undef int_tp
#endif  //int_tp
#define int_tp int32_t
#ifdef uint_tp
#undef uint_tp
#endif  //uint_tp
#define uint_tp uint32_t
#ifdef int_tpc
#undef int_tpc
#endif  //int_tpc
#define int_tpc int32_t
#ifdef uint_tpc
#undef uint_tpc
#endif  //uint_tpc
#define uint_tpc uint32_t
#ifdef HALF_SUPPORT_AVAILABLE
#ifdef Dtype
#undef Dtype
#endif  //Dtype
#define Dtype half
__kernel
void caffe_gpu_im2col(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, const int32_t height, const int32_t width, const int32_t kernel_h, const int32_t kernel_w, const int32_t pad_h, const int32_t pad_w, const int32_t stride_h, const int32_t stride_w, const int32_t dilation_h, const int32_t dilation_w, const int32_t height_col, const int32_t width_col, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
const int_tp h_index = index / width_col;
const int_tp h_col = h_index % height_col;
const int_tp w_col = index % width_col;
const int_tp c_im = h_index / height_col;
const int_tp c_col = c_im * kernel_h * kernel_w;
const int_tp h_offset = h_col * stride_h - pad_h;
const int_tp w_offset = w_col * stride_w - pad_w;
__global Dtype* data_col_ptr = data_col;
data_col_ptr += (c_col * height_col + h_col) * width_col + w_col;
__global const Dtype* data_im_ptr = data_im;
data_im_ptr += (c_im * height + h_offset) * width + w_offset;
for (int_tp i = 0; i < kernel_h; ++i) {
for (int_tp j = 0; j < kernel_w; ++j) {
int_tp h_im = h_offset + i * dilation_h;
int_tp w_im = w_offset + j * dilation_w;
*data_col_ptr = (h_im >= 0 && w_im >= 0 && h_im < height && w_im < width) ?data_im_ptr[i * dilation_h * width + j * dilation_w] : (Dtype)0;
data_col_ptr += height_col * width_col;
}
}
}
}
__kernel
void caffe_gpu_col2im(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, const int32_t height, const int32_t width, const int32_t channels, const int32_t kernel_h, const int32_t kernel_w, const int32_t pad_h, const int32_t pad_w, const int32_t stride_h, const int32_t stride_w, const int32_t dilation_h, const int32_t dilation_w, const int32_t height_col, const int32_t width_col, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {
Dtype val = 0;
const int_tp w_im = index % width + pad_w;
const int_tp h_im = (index / width) % height + pad_h;
const int_tp c_im = index / (width * height);
int_tp kernel_extent_w = (kernel_w - 1) * dilation_w + 1;
int_tp kernel_extent_h = (kernel_h - 1) * dilation_h + 1;
const int_tp w_col_start = (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;
const int_tp w_col_end = min(w_im / stride_w + 1, width_col);
const int_tp h_col_start = (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;
const int_tp h_col_end = min(h_im / stride_h + 1, height_col);
for (int_tp h_col = h_col_start; h_col < h_col_end; h_col += 1) {
for (int_tp w_col = w_col_start; w_col < w_col_end; w_col += 1) {
int_tp h_k = (h_im - h_col * stride_h);
int_tp w_k = (w_im - w_col * stride_w);
if (h_k % dilation_h == 0 && w_k % dilation_w == 0) {
h_k /= dilation_h;
w_k /= dilation_w;
int_tp data_col_index = (((c_im * kernel_h + h_k) * kernel_w + w_k) * height_col + h_col) * width_col + w_col;
val += data_col[data_col_index];
}
}
}
data_im[index] = val;
}
}
__kernel
void caffe_gpu_im2col_nd_1(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[1];
int_tp d_iter[1];
__local int_tp shared_dilation[1];
__local int_tp shared_kernel_shape[1];
__local int_tp shared_pad[1];
__local int_tp shared_stride[1];
__local int_tp shared_col_shape[2];
__local int_tp shared_im_shape[2];
for(int_tp li = get_local_id(0); li < 1; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 2; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 0; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 1; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 1; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 1; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 0; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 0; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_1(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[1];
int_tp d_col_iter[1];
int_tp d_col_start[1];
int_tp d_col_end[1];
__local int_tp shared_dilation[1];
__local int_tp shared_kernel_shape[1];
__local int_tp shared_pad[1];
__local int_tp shared_stride[1];
__local int_tp shared_col_shape[2];
__local int_tp shared_im_shape[2];
for(int_tp li = get_local_id(0); li < 1;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 2;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 0; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 1; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 0; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 1; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 0; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
__kernel
void caffe_gpu_im2col_nd_2(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[2];
int_tp d_iter[2];
__local int_tp shared_dilation[2];
__local int_tp shared_kernel_shape[2];
__local int_tp shared_pad[2];
__local int_tp shared_stride[2];
__local int_tp shared_col_shape[3];
__local int_tp shared_im_shape[3];
for(int_tp li = get_local_id(0); li < 2; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 3; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 1; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 2; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 2; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 2; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 1; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 1; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_2(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[2];
int_tp d_col_iter[2];
int_tp d_col_start[2];
int_tp d_col_end[2];
__local int_tp shared_dilation[2];
__local int_tp shared_kernel_shape[2];
__local int_tp shared_pad[2];
__local int_tp shared_stride[2];
__local int_tp shared_col_shape[3];
__local int_tp shared_im_shape[3];
for(int_tp li = get_local_id(0); li < 2;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 3;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 1; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 2; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 1; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 2; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 1; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
__kernel
void caffe_gpu_im2col_nd_3(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[3];
int_tp d_iter[3];
__local int_tp shared_dilation[3];
__local int_tp shared_kernel_shape[3];
__local int_tp shared_pad[3];
__local int_tp shared_stride[3];
__local int_tp shared_col_shape[4];
__local int_tp shared_im_shape[4];
for(int_tp li = get_local_id(0); li < 3; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 4; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 2; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 3; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 3; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 3; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 2; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 2; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_3(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[3];
int_tp d_col_iter[3];
int_tp d_col_start[3];
int_tp d_col_end[3];
__local int_tp shared_dilation[3];
__local int_tp shared_kernel_shape[3];
__local int_tp shared_pad[3];
__local int_tp shared_stride[3];
__local int_tp shared_col_shape[4];
__local int_tp shared_im_shape[4];
for(int_tp li = get_local_id(0); li < 3;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 4;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 2; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 3; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 2; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 3; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 2; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
__kernel
void caffe_gpu_im2col_nd_4(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[4];
int_tp d_iter[4];
__local int_tp shared_dilation[4];
__local int_tp shared_kernel_shape[4];
__local int_tp shared_pad[4];
__local int_tp shared_stride[4];
__local int_tp shared_col_shape[5];
__local int_tp shared_im_shape[5];
for(int_tp li = get_local_id(0); li < 4; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 5; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 3; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 4; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 4; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 4; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 3; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 3; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_4(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[4];
int_tp d_col_iter[4];
int_tp d_col_start[4];
int_tp d_col_end[4];
__local int_tp shared_dilation[4];
__local int_tp shared_kernel_shape[4];
__local int_tp shared_pad[4];
__local int_tp shared_stride[4];
__local int_tp shared_col_shape[5];
__local int_tp shared_im_shape[5];
for(int_tp li = get_local_id(0); li < 4;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 5;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 3; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 4; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 3; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 4; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 3; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
__kernel
void caffe_gpu_im2col_nd_5(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[5];
int_tp d_iter[5];
__local int_tp shared_dilation[5];
__local int_tp shared_kernel_shape[5];
__local int_tp shared_pad[5];
__local int_tp shared_stride[5];
__local int_tp shared_col_shape[6];
__local int_tp shared_im_shape[6];
for(int_tp li = get_local_id(0); li < 5; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 6; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 4; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 5; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 5; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 5; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 4; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 4; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_5(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[5];
int_tp d_col_iter[5];
int_tp d_col_start[5];
int_tp d_col_end[5];
__local int_tp shared_dilation[5];
__local int_tp shared_kernel_shape[5];
__local int_tp shared_pad[5];
__local int_tp shared_stride[5];
__local int_tp shared_col_shape[6];
__local int_tp shared_im_shape[6];
for(int_tp li = get_local_id(0); li < 5;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 6;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 4; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 5; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 4; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 5; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 4; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
__kernel
void caffe_gpu_im2col_nd_6(const int32_t n, __global const half* data_im_raw_ptr, const uint_tp data_im_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_col_raw_ptr, const uint_tp data_col_offset) {
__global const half* data_im = data_im_raw_ptr + data_im_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_col = data_col_raw_ptr + data_col_offset;
int_tp d_temp[6];
int_tp d_iter[6];
__local int_tp shared_dilation[6];
__local int_tp shared_kernel_shape[6];
__local int_tp shared_pad[6];
__local int_tp shared_stride[6];
__local int_tp shared_col_shape[7];
__local int_tp shared_im_shape[7];
for(int_tp li = get_local_id(0); li < 6; li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 7; li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
int_tp i;
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp channel_in = index;
int_tp channel_out = 1;
for (i = 5; i >= 0; --i) {
d_temp[i] = channel_in % shared_col_shape[i + 1];
channel_in /= shared_col_shape[i + 1];
channel_out *= shared_kernel_shape[i];
}
channel_out *= channel_in;
int_tp data_col_inc = 1;
for (i = 0; i < 6; ++i) {
channel_out *= shared_col_shape[i + 1];
channel_out += d_temp[i];
d_temp[i] = d_temp[i] * shared_stride[i] - shared_pad[i];
channel_in *= shared_im_shape[i + 1];
channel_in += d_temp[i];
data_col_inc *= shared_col_shape[i + 1];
d_iter[i] = 0;
}
__global Dtype* data_col_ptr = data_col + channel_out;
__global const Dtype* data_im_ptr = data_im + channel_in;
bool incremented;
do {
bool in_range = true;
for (i = 0; i < 6; ++i) {
const int_tp d_iter_im = d_iter[i] * shared_dilation[i] + d_temp[i];
in_range &= d_iter_im >= 0 && d_iter_im < shared_im_shape[i + 1];
if (!in_range) { break; }
}
if (in_range) {
int_tp data_im_offset = d_iter[0] * shared_dilation[0];
for (i = 1; i < 6; ++i) {
data_im_offset *= shared_im_shape[i + 1];
data_im_offset += d_iter[i] * shared_dilation[i];
}
*data_col_ptr = data_im_ptr[data_im_offset];
} else {
*data_col_ptr = 0;
}
data_col_ptr += data_col_inc;
incremented = false;
for (i = 5; i >= 0; --i) {
const int_tp d_max = shared_kernel_shape[i];
if (d_iter[i] == d_max - 1) {
d_iter[i] = 0;
} else {
++d_iter[i];
incremented = true;
break;
}
}  // for (int_tp i = 5; i >= 0; --i)
} while (incremented);
}
}
__kernel
void caffe_gpu_col2im_nd_6(const int32_t n, __global const half* data_col_raw_ptr, const uint_tp data_col_offset, __global const int32_t* im_shape_raw_ptr, const uint_tp im_shape_offset, __global const int32_t* col_shape_raw_ptr, const uint_tp col_shape_offset, __global const int32_t* kernel_shape, __global const int32_t* pad, __global const int32_t* stride, __global const int32_t* dilation, __global half* data_im_raw_ptr, const uint_tp data_im_offset) {
__global const half* data_col = data_col_raw_ptr + data_col_offset;
__global const int32_t* im_shape = im_shape_raw_ptr + im_shape_offset;
__global const int32_t* col_shape = col_shape_raw_ptr + col_shape_offset;
__global half* data_im = data_im_raw_ptr + data_im_offset;
int_tp d_im[6];
int_tp d_col_iter[6];
int_tp d_col_start[6];
int_tp d_col_end[6];
__local int_tp shared_dilation[6];
__local int_tp shared_kernel_shape[6];
__local int_tp shared_pad[6];
__local int_tp shared_stride[6];
__local int_tp shared_col_shape[7];
__local int_tp shared_im_shape[7];
for(int_tp li = get_local_id(0); li < 6;li += get_local_size(0)) {
shared_dilation[li] = dilation[li];
shared_kernel_shape[li] = kernel_shape[li];
shared_pad[li] = pad[li];
shared_stride[li] = stride[li];
}
for(int_tp li = get_local_id(0); li < 7;li += get_local_size(0)) {
shared_col_shape[li] = col_shape[li];
shared_im_shape[li] = im_shape[li];
}
barrier(CLK_LOCAL_MEM_FENCE);
for (int_tp index = get_global_id(0); index < (n); index += get_global_size(0)) {

int_tp c_im = index;
for (int_tp i = 5; i >= 0; --i) {
d_im[i] = c_im % shared_im_shape[i + 1] + shared_pad[i];
c_im /= shared_im_shape[i + 1];
}
bool done = false;
for (int_tp i = 0; i < 6; ++i) {
const int_tp kernel_extent = shared_dilation[i] * (shared_kernel_shape[i] - 1) + 1;
d_col_start[i] = d_col_iter[i] =(d_im[i] < kernel_extent) ? 0 :(d_im[i] - kernel_extent) / shared_stride[i] + 1;
d_col_end[i] =min(d_im[i] / shared_stride[i] + 1, shared_col_shape[i + 1]);
if (d_col_start[i] >= d_col_end[i]) {
data_im[index] = (Dtype)0.0;
done = true;
break;  // for (int_tp i = 0; i < num_axes; ++i)
}
}
if (!done) {
Dtype val = (Dtype)0.0;
bool incremented = true;
bool skip = false;
do {
int_tp final_offset = 0;
int_tp kernel_shape_prod = 1;
int_tp kernel_index;
for (int_tp i = 5; i >= 0; --i) {
kernel_index = d_im[i] - d_col_iter[i] * shared_stride[i];
if (kernel_index % shared_dilation[i]) {
skip = true;
break;
} else {
kernel_index /= shared_dilation[i];
final_offset += kernel_index * kernel_shape_prod;
kernel_shape_prod *= shared_kernel_shape[i];
}
}
if (!skip) {
final_offset += kernel_shape_prod * c_im;
for (int_tp i = 0; i < 6; ++i) {
final_offset *= shared_col_shape[i + 1];
final_offset += d_col_iter[i];
}
val += data_col[final_offset];
}
skip = false;
incremented = false;
for (int_tp i = 5; i >= 0; --i) {
const int_tp d_max = d_col_end[i];
if (d_col_iter[i] == d_max - 1) {
d_col_iter[i] = d_col_start[i];
} else {
++d_col_iter[i];
incremented = true;
break;
}
}
} while (incremented);
data_im[index] = val;
}
}
}
#endif  // HALF_SUPPORT_AVAILABLE

